{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FUSION WORK - OCULAR_DISEASE_AUGMENTATION_CLAHE.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aditidagar/ocular_disease_recog/blob/main/PREPROCESSING/FINAL_FUSION_WORK_OCULAR_DISEASE_AUGMENTATION_CLAHE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48MCNdQNXoXG"
      },
      "source": [
        "NOTE: This script is forked from Grezgor Meller's work: https://github.com/GrzegorzMeller/AlgorithmsForMassiveData/blob/master/Preprocessing/OCULAR_DISEASE_AUGMENTATION.ipynb\n",
        "\n",
        "Modifications were made to account for image fusion methods, though we had planned to improve the augmentation process further by using Albumentations. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9CATT2uywzBd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54d5fd4b-6278-4d2c-da40-22cee156ebc2"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/amd/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /amd/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3ZRWzpwWroY"
      },
      "source": [
        "NOTE: We assume you have a directory called \"ML490\" in your Google Drive which contains the pre-processed data. If you do not, adjust the path below to point to the pre-processed data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myo7rbQUbqC6"
      },
      "source": [
        "!cp /amd/My\\ Drive/ML490/ODIR-5K_contrast.zip /content/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oO4ofIQeNy8x"
      },
      "source": [
        "!unzip ODIR-5K_contrast.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OAAe9eGbEvey",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7dbb051a-cc25-42a1-c0a3-56cc9b9e5e1b"
      },
      "source": [
        "import glob\n",
        "def show_class_distribution():\n",
        "  N = 0\n",
        "  D=0\n",
        "  G=0\n",
        "  C=0\n",
        "  A=0\n",
        "  H=0\n",
        "  M=0\n",
        "  O = 0\n",
        "  X = 0\n",
        "  for element in glob.glob(\"ODIR-5K/Training Images/*.jpg\"):\n",
        "    img_name = element.split(\"/\")[-1]\n",
        "    img_label = img_name.split(\"-\")\n",
        "    if img_label[-1] == \"N.jpg\":\n",
        "      N += 1\n",
        "    elif img_label[-1] == \"D.jpg\":\n",
        "      D +=1\n",
        "    elif img_label[-1] == \"G.jpg\":\n",
        "      G +=1\n",
        "    elif img_label[-1] == \"C.jpg\":\n",
        "      C +=1\n",
        "    elif img_label[-1] == \"A.jpg\":\n",
        "      A +=1\n",
        "    elif img_label[-1] == \"H.jpg\":\n",
        "      H +=1\n",
        "    elif img_label[-1] == \"M.jpg\":\n",
        "      M +=1\n",
        "    elif img_label[-1] == \"O.jpg\":\n",
        "      O +=1\n",
        "    elif \"&\" in img_label[-1]:\n",
        "      X +=1  \n",
        "  print(N, D, G, C, A, H, M, O, X)\n",
        "show_class_distribution()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1999 991 149 173 159 62 166 536 379\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJ8R3uSczqS2"
      },
      "source": [
        "# Only one of these lines should be uncommented, depending on which image fusion method you are using. It must be consistent with the fusionMethod variable used in the pre-processing script\n",
        "# fusionMethod = \"CONCAT\"\n",
        "# fusionMethod = \"SUM\"\n",
        " fusionMethod = \"NONE\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGUrR8NUwM4W"
      },
      "source": [
        "import cv2 as cv\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from PIL import Image, ImageEnhance\n",
        "\n",
        "\n",
        "if fusionMethod == \"CONCAT\":\n",
        "  # We can't rotate images when using concatenation fusion method since the images are rectangular\n",
        "  MAX_ROTATE = 0\n",
        "else:\n",
        "  MAX_ROTATE = 10\n",
        "\n",
        "def cv2_clipped_zoom(img, zoom_factor):\n",
        "    height, width = img.shape[:2] # It's also the final desired shape\n",
        "    new_height, new_width = int(height * zoom_factor), int(width * zoom_factor)\n",
        "    y1, x1 = max(0, new_height - height) // 2, max(0, new_width - width) // 2\n",
        "    y2, x2 = y1 + height, x1 + width\n",
        "    bbox = np.array([y1,x1,y2,x2])\n",
        "    # Map back to original image coordinates\n",
        "    bbox = (bbox / zoom_factor).astype(np.int)\n",
        "    y1, x1, y2, x2 = bbox\n",
        "    cropped_img = img[y1:y2, x1:x2]\n",
        "\n",
        "    # Handle padding when downscaling\n",
        "    resize_height, resize_width = min(new_height, height), min(new_width, width)\n",
        "    pad_height1, pad_width1 = (height - resize_height) // 2, (width - resize_width) //2\n",
        "    pad_height2, pad_width2 = (height - resize_height) - pad_height1, (width - resize_width) - pad_width1\n",
        "    pad_spec = [(pad_height1, pad_height2), (pad_width1, pad_width2)] + [(0,0)] * (img.ndim - 2)\n",
        "\n",
        "    result = cv.resize(cropped_img, (resize_width, resize_height))\n",
        "    result = np.pad(result, pad_spec, mode='constant')\n",
        "    assert result.shape[0] == height and result.shape[1] == width\n",
        "    return result\n",
        "\n",
        "def aumgent_9(impath):\n",
        "  img = cv.imread(impath,1)\n",
        "  im1 = cv.flip(img, 0) #Vertical Flip\n",
        "  im2 = cv.flip(img, 1) #Horizontal Flip\n",
        "  im3 = cv.flip(img, -1) #Flip Both\n",
        "  im4 = cv2_clipped_zoom(img, random.uniform(0.9,1.2))\n",
        "  im5 = cv2_clipped_zoom(im1, random.uniform(0.9,1.2))\n",
        "  file_name = impath.split('/')\n",
        "  new_path = file_name[-1].split('-') \n",
        "  cv.imwrite(\"ODIR-5K/Training Images/\"+new_path[0]+\"VF-\"+new_path[1],im1)\n",
        "  cv.imwrite(\"ODIR-5K/Training Images/\"+new_path[0]+\"HF-\"+new_path[1],im2)\n",
        "  cv.imwrite(\"ODIR-5K/Training Images/\"+new_path[0]+\"BF-\"+new_path[1],im3)\n",
        "  cv.imwrite(\"ODIR-5K/Training Images/\"+new_path[0]+\"ZM-\"+new_path[1],im4)\n",
        "  cv.imwrite(\"ODIR-5K/Training Images/\"+new_path[0]+\"VFZM-\"+new_path[1],im5)\n",
        "  #image random rotating and brightening using PIL\n",
        "  img_org = Image.open(impath)\n",
        "  enhancer = ImageEnhance.Brightness(img_org)\n",
        "  im6 = enhancer.enhance(random.uniform(1.0,1.3))\n",
        "  im7 = img_org.rotate(random.uniform(0,MAX_ROTATE))\n",
        "  img_ver = Image.open(\"ODIR-5K/Training Images/\"+new_path[0]+\"VF-\"+new_path[1])\n",
        "  im8 = img_ver.rotate(random.uniform(0,MAX_ROTATE))\n",
        "  im6.save(\"ODIR-5K/Training Images/\"+new_path[0]+\"RB-\"+new_path[1])\n",
        "  im7.save(\"ODIR-5K/Training Images/\"+new_path[0]+\"RR-\"+new_path[1])\n",
        "  im8.save(\"ODIR-5K/Training Images/\"+new_path[0]+\"VFRR-\"+new_path[1])\n",
        "\n",
        "#for H class that has the smallest set\n",
        "def aumgent_20(impath):\n",
        "  img = cv.imread(impath,1)\n",
        "  im1 = cv.flip(img, 0) #Vertical Flip\n",
        "  im2 = cv.flip(img, 1) #Horizontal Flip\n",
        "  im3 = cv.flip(img, -1) #Both Flip\n",
        "  im4 = cv2_clipped_zoom(img, random.uniform(0.9,1.2))\n",
        "  im5 = cv2_clipped_zoom(im1, random.uniform(0.9,1.2))\n",
        "  im6 = cv2_clipped_zoom(im2, random.uniform(0.9,1.2))\n",
        "  im7 = cv2_clipped_zoom(im3, random.uniform(0.9,1.2))\n",
        "  file_name = impath.split('/')\n",
        "  new_path = file_name[-1].split('-') \n",
        "  cv.imwrite(\"ODIR-5K/Training Images/\"+new_path[0]+\"VF-\"+new_path[1],im1)\n",
        "  cv.imwrite(\"ODIR-5K/Training Images/\"+new_path[0]+\"HF-\"+new_path[1],im2)\n",
        "  cv.imwrite(\"ODIR-5K/Training Images/\"+new_path[0]+\"BF-\"+new_path[1],im3)\n",
        "  cv.imwrite(\"ODIR-5K/Training Images/\"+new_path[0]+\"ZM-\"+new_path[1],im4)\n",
        "  cv.imwrite(\"ODIR-5K/Training Images/\"+new_path[0]+\"VFZM-\"+new_path[1],im5)\n",
        "  cv.imwrite(\"ODIR-5K/Training Images/\"+new_path[0]+\"HFZM-\"+new_path[1],im6)\n",
        "  cv.imwrite(\"ODIR-5K/Training Images/\"+new_path[0]+\"BFZM-\"+new_path[1],im7)\n",
        "  #image random rotating and brightening using PIL\n",
        "  img_org = Image.open(impath)\n",
        "  enhancer = ImageEnhance.Brightness(img_org)\n",
        "  im7 = enhancer.enhance(random.uniform(0.9,1.2))\n",
        "  im8 = img_org.rotate(random.uniform(0,MAX_ROTATE))\n",
        "  img_ver = Image.open(\"ODIR-5K/Training Images/\"+new_path[0]+\"VF-\"+new_path[1])\n",
        "  im9 = img_ver.rotate(random.uniform(0,MAX_ROTATE))\n",
        "  im10 = ImageEnhance.Brightness(im9).enhance(random.uniform(0.9,1.2))\n",
        "  im11 =  ImageEnhance.Brightness(img_ver).enhance(random.uniform(0.9,1.2))\n",
        "  img_hor = Image.open(\"ODIR-5K/Training Images/\"+new_path[0]+\"HF-\"+new_path[1])\n",
        "  im12 = img_hor.rotate(random.uniform(0,MAX_ROTATE))\n",
        "  im13 = ImageEnhance.Brightness(im12).enhance(random.uniform(0.9,1.2))\n",
        "  im14 = ImageEnhance.Brightness(img_hor).enhance(random.uniform(0.9,1.2))\n",
        "  im_bfl =  Image.open(\"ODIR-5K/Training Images/\"+new_path[0]+\"BF-\"+new_path[1])\n",
        "  im15 = im_bfl.rotate(random.uniform(0,MAX_ROTATE))\n",
        "  im16 = ImageEnhance.Brightness(im15).enhance(random.uniform(0.9,1.2))\n",
        "  im17 = ImageEnhance.Brightness(im_bfl).enhance(random.uniform(0.9,1.2))\n",
        "  im_zom =  Image.open(\"ODIR-5K/Training Images/\"+new_path[0]+\"ZM-\"+new_path[1])\n",
        "  im18 = im_zom.rotate(random.uniform(0,MAX_ROTATE))\n",
        "  im19 = ImageEnhance.Brightness(im18).enhance(random.uniform(0.9,1.2))\n",
        "  im20 = ImageEnhance.Brightness(im_zom).enhance(random.uniform(0.9,1.2))\n",
        "\n",
        "  im7.save(\"ODIR-5K/Training Images/\"+new_path[0]+\"RB-\"+new_path[1])\n",
        "  im8.save(\"ODIR-5K/Training Images/\"+new_path[0]+\"RR-\"+new_path[1])\n",
        "  im9.save(\"ODIR-5K/Training Images/\"+new_path[0]+\"VFRR-\"+new_path[1])\n",
        "  im10.save(\"ODIR-5K/Training Images/\"+new_path[0]+\"VFRRRB-\"+new_path[1])\n",
        "  im11.save(\"ODIR-5K/Training Images/\"+new_path[0]+\"VFRB-\"+new_path[1])\n",
        "  im12.save(\"ODIR-5K/Training Images/\"+new_path[0]+\"HFRR-\"+new_path[1])\n",
        "  im13.save(\"ODIR-5K/Training Images/\"+new_path[0]+\"HFRRRB-\"+new_path[1])\n",
        "  im14.save(\"ODIR-5K/Training Images/\"+new_path[0]+\"HFRB-\"+new_path[1])\n",
        "  im15.save(\"ODIR-5K/Training Images/\"+new_path[0]+\"BFRR-\"+new_path[1])\n",
        "  im16.save(\"ODIR-5K/Training Images/\"+new_path[0]+\"BFRRRB-\"+new_path[1])\n",
        "  im17.save(\"ODIR-5K/Training Images/\"+new_path[0]+\"BFRB-\"+new_path[1])\n",
        "  im18.save(\"ODIR-5K/Training Images/\"+new_path[0]+\"ZMRR-\"+new_path[1])\n",
        "  im19.save(\"ODIR-5K/Training Images/\"+new_path[0]+\"ZMRRRB-\"+new_path[1])\n",
        "  im20.save(\"ODIR-5K/Training Images/\"+new_path[0]+\"ZMRB-\"+new_path[1])\n",
        "\n",
        "#aumgent_1 will be applied to class D and O, since they don't need to be aumgmented so much in order to balance the dataset\n",
        "def aumgent_1(impath):\n",
        "  img = cv.imread(impath,0)\n",
        "  im1 = cv.flip(img, 0) #Vertical Flip\n",
        "  file_name = impath.split('/')\n",
        "  new_path = file_name[-1].split('-') \n",
        "  cv.imwrite(\"ODIR-5K/Training Images/\"+new_path[0]+\"VF-\"+new_path[1],im1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JTaddqNubivK"
      },
      "source": [
        "labels = [\"G.jpg\", \"C.jpg\", \"A.jpg\",\"M.jpg\"]\n",
        "labels2 = [\"D.jpg\", \"O.jpg\"]\n",
        "\n",
        "# Augment data for diseases with a lower count of images\n",
        "for element in glob.glob(\"ODIR-5K/Training Images/*.jpg\"):\n",
        "  file_name = element.split('/')\n",
        "  new_path = file_name[-1].split('-')\n",
        "  if new_path[-1] ==\"H.jpg\":\n",
        "    aumgent_20(element)\n",
        "  else:\n",
        "    for l in labels:\n",
        "      if new_path[-1] == l:\n",
        "        aumgent_9(element)\n",
        "    for l in labels2:\n",
        "      if new_path[-1] == l:\n",
        "        aumgent_1(element)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4OCwrtbsGxdI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc4aca37-7588-408c-bfd2-80faf9bbdbb7"
      },
      "source": [
        "show_class_distribution()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1999 1982 1341 1557 1431 1364 1494 1072 379\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOC4fYGnHJa_"
      },
      "source": [
        "!zip -r ODIR-5K_aug_contrast.zip ODIR-5K/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BsAztLMvYM07"
      },
      "source": [
        "NOTE: We assume you have a directory called \"ML490\" in your Google Drive where the augmented data will be stored. If you do not, adjust the path below to point to where you will save it. If you change it, you must make a modification in the model script(s) to account for this path change"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNP0E8AwIxPC"
      },
      "source": [
        "!cp -r ODIR-5K_aug_contrast.zip /amd/My\\ Drive/ML490"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DW81gIAnEY9m"
      },
      "source": [
        "!rm -rf ODIR-5K/"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}