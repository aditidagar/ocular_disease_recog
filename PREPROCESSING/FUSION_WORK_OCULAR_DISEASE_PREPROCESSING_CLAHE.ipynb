{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FUSION WORK - OCULAR_DISEASE_PREPROCESSING_CLAHE.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aditidagar/ocular_disease_recog/blob/main/PREPROCESSING/FUSION_WORK_OCULAR_DISEASE_PREPROCESSING_CLAHE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmUUgbNbAVjE"
      },
      "source": [
        "!echo '{\"username\":\"arturusmaximus\",\"key\":\"4f14194978499e9ae1ad6adb74b94add\"}' > /content/kaggle.json\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!kaggle datasets download -d andrewmvd/ocular-disease-recognition-odir5k\n",
        "!unzip ocular-disease-recognition-odir5k.zip\n",
        "!mv ODIR-5K ODIR-5K_old\n",
        "!mv ODIR-5K_old/ODIR-5K ODIR-5K\n",
        "!mkdir ODIR-5K/Validation_Images\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-mukUUUxAl7U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f40a2c03-5557-4873-b1be-49a133416071"
      },
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import os\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import IPython.display as display\n",
        "import numpy as np\n",
        "import glob\n",
        "import random\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "CLASS_NAMES = ['N', 'D', 'G', 'C', 'A', 'H', 'M', 'O']\n",
        "\n",
        "# Set a random seed so we always use the same validation set (which is randomly sampled from dataset)\n",
        "random.seed(7)\n",
        "\n",
        "training_images_file = 'ODIR-5K/Training Images'\n",
        "testing_images_file = 'ODIR-5K/Testing Images'\n",
        "labels_file = 'ODIR-5K/data.xlsx'\n",
        "\n",
        "diseases = {'abnormal pigment ': 'O', 'age-related macular degeneration': 'A', 'anterior segment image': 'DELETE', 'arteriosclerosis': 'O', 'asteroid hyalosis': 'O', 'atrophic change': 'O', 'atrophy': 'O', 'branch retinal artery occlusion': 'O', 'branch retinal vein occlusion': 'O', 'cataract': 'C', 'central retinal artery occlusion': 'O', 'central retinal vein occlusion': 'O', 'central serous chorioretinopathy': 'O', 'chorioretinal atrophy': 'O', 'chorioretinal atrophy with pigmentation proliferation': 'O', 'choroidal nevus': 'NaN', 'congenital choroidal coloboma': 'O', 'depigmentation of the retinal pigment epithelium': 'O', 'diabetic retinopathy': 'D', 'diffuse chorioretinal atrophy': 'O', 'diffuse retinal atrophy': 'O', 'drusen': 'O', 'dry age-related macular degeneration': 'A', 'epiretinal membrane': 'O', 'epiretinal membrane over the macula': 'O', 'fundus laser photocoagulation spots': 'O', 'glaucoma': 'G', 'glial remnants anterior to the optic disc': 'O', 'hypertensive retinopathy': 'H', 'hypertensive retinopathy,diabetic retinopathy': 'D', 'idiopathic choroidal neovascularization': 'O', 'image offset': 'DELETE', 'intraretinal hemorrhage': 'O', 'intraretinal microvascular abnormality': 'O', 'laser spot': 'O', 'lens dust': 'DELETE', 'low image quality': 'DELETE', 'low image quality,maculopathy': 'DELETE', 'macular coloboma': 'O', 'macular epiretinal membrane': 'O', 'macular hole': 'O', 'macular pigmentation disorder': 'NaN', 'maculopathy': 'O', 'mild nonproliferative retinopathy': 'D', 'moderate non proliferative retinopathy': 'D', 'morning glory syndrome': 'O', 'myelinated nerve fibers': 'O', 'myopia retinopathy': 'M', 'myopic maculopathy': 'M', 'myopic retinopathy': 'M', 'no fundus image': 'DELETE', 'normal fundus': 'N', 'old branch retinal vein occlusion': 'O', 'old central retinal vein occlusion': 'O', 'old chorioretinopathy': 'O', 'old choroiditis': 'O', 'optic disc edema': 'O', 'optic discitis': 'O', 'optic disk epiretinal membrane': 'O', 'optic disk photographically invisible': 'DELETE', 'optic nerve atrophy': 'O', 'oval yellow-white atrophy': 'O', 'pathological myopia': 'M', 'peripapillary atrophy': 'O', 'pigment epithelium proliferation': 'O', 'pigmentation disorder': 'O', 'post laser photocoagulation': 'O', 'post retinal laser surgery': 'O', 'proliferative diabetic retinopathy': 'D', 'punctate inner choroidopathy': 'O', 'refractive media opacity': 'O', 'retina fold': 'O', 'retinal artery macroaneurysm': 'O', 'retinal detachment': 'O', 'retinal pigment epithelial hypertrophy': 'O', 'retinal pigment epithelium atrophy': 'O', 'retinal pigmentation': 'O', 'retinal vascular sheathing': 'O', 'retinitis pigmentosa': 'O', 'retinochoroidal coloboma': 'O', 'rhegmatogenous retinal detachment': 'O', 'severe nonproliferative retinopathy': 'D', 'severe proliferative diabetic retinopathy': 'D', 'silicone oil eye': 'O', 'spotted membranous change': 'O', 'suspected abnormal color of  optic disc': 'O', 'suspected cataract': 'C', 'suspected diabetic retinopathy': 'D', 'suspected glaucoma': 'G', 'suspected macular epimacular membrane': 'O', 'suspected microvascular anomalies': 'O', 'suspected moderate non proliferative retinopathy': 'D', 'suspected retinal vascular sheathing': 'O', 'suspected retinitis pigmentosa': 'O', 'suspicious diabetic retinopathy': 'D', 'tessellated fundus': 'O', 'vascular loops': 'O', 'vessel tortuosity': 'O', 'vitreous degeneration': 'O', 'vitreous opacity': 'O', 'wedge white line change': 'O', 'wedge-shaped change': 'O', 'wet age-related macular degeneration': 'A', 'white vessel': 'O'}\n",
        "\n",
        "#load labels to pandas\n",
        "labels = pd.read_excel(labels_file, index_col=0) \n",
        "print(labels['Left-Diagnostic Keywords'][0])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cataract\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "480GR6KOBj0C"
      },
      "source": [
        "Labeling Images by renaming them, removing low quality images "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KrYR14THAo4o"
      },
      "source": [
        "file_path = 'ODIR-5K/Training Images'\n",
        "all_paths = []\n",
        "for element in glob.glob(file_path+\"/*.jpg\"):\n",
        "  all_paths.append(element)\n",
        "paths = []\n",
        "\n",
        "# TODO: Count how many matching eye images?\n",
        "\n",
        "#adding label information to image names\n",
        "for u_id in labels.index:\n",
        "  labelL = \"\"\n",
        "  labelR = \"\"\n",
        "  diagnosticL = labels['Left-Diagnostic Keywords'][u_id]\n",
        "  diagnosticR = labels['Right-Diagnostic Keywords'][u_id]\n",
        "  diagnosticL = diagnosticL.split(\"，\") \n",
        "  diagnosticR = diagnosticR.split(\"，\") \n",
        "  for d in diagnosticL:\n",
        "    if d in diseases:\n",
        "        if labelL != \"\":\n",
        "          labelL+=\"&\"+diseases[d]\n",
        "        else:\n",
        "          labelL+=diseases[d]\n",
        "    else:\n",
        "        labelL+=\"DELETE\"\n",
        "  for d in diagnosticR:\n",
        "    if d in diseases:\n",
        "      if labelR != \"\":\n",
        "        labelR+=\"&\"+diseases[d]\n",
        "      else:\n",
        "        labelR+=diseases[d]\n",
        "    else:\n",
        "      labelR+=\"DELETE\"\n",
        "\n",
        "  if file_path+\"/\"+str(labels['Left-Fundus'][u_id]) in all_paths:\n",
        "    filename = str(labels['Left-Fundus'][u_id]).split(\".\")\n",
        "    os.rename(file_path+\"/\"+str(labels['Left-Fundus'][u_id]), file_path+\"/\"+filename[0]+\"-\"+labelL+\".jpg\")\n",
        "    paths.append(file_path+\"/\"+str(labels['Left-Fundus'][u_id])+\"/\"+labelL)\n",
        "\n",
        "  if file_path+\"/\"+str(labels['Right-Fundus'][u_id]) in all_paths:\n",
        "    filename = str(labels['Right-Fundus'][u_id]).split(\".\")\n",
        "    os.rename(file_path+\"/\"+str(labels['Right-Fundus'][u_id]), file_path+\"/\"+filename[0]+\"-\"+labelR+\".jpg\")\n",
        "    paths.append(file_path+\"/\"+str(labels['Right-Fundus'][u_id])+\"/\"+labelR)\n",
        "\n",
        "#deleting low quality images    \n",
        "items_to_remove = []\n",
        "add_mix_info = []\n",
        "\n",
        "for element in glob.glob(\"ODIR-5K/Training Images/*.jpg\"):\n",
        "    img_name = element.split(\"/\")[-1]\n",
        "    img_label = img_name.split(\"-\")\n",
        "    if \"DELETE\" in img_label[-1]:\n",
        "      items_to_remove.append(element)\n",
        "    elif \"&\" in img_label[-1]:\n",
        "      add_mix_info.append(element)\n",
        "\n",
        "for e in items_to_remove:\n",
        "  os.remove(e)\n",
        "\n",
        "for e in add_mix_info:\n",
        "  pom = e.split(\".\")\n",
        "  os.rename(e, pom[0]+\"&X\"+\".jpg\")      "
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEqFJtkJBaaC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3d019720",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f97af4a6-18bc-4df3-8afa-7184f3330db5"
      },
      "source": [
        "!pip install -q -U albumentations\n",
        "!echo \"$(pip freeze | grep albumentations) is successfully installed\""
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 102 kB 5.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 47.6 MB 66 kB/s \n",
            "\u001b[?25halbumentations==1.1.0 is successfully installed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FFevHeGTEuml"
      },
      "source": [
        "Image Enhancement and Resizing. Creation of Validation Set by Random Selection\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6BLEIpj-Etpj"
      },
      "source": [
        "import cv2 as cv\n",
        "import albumentations as A\n",
        "\n",
        "fusionMethod = \"SUM\"\n",
        "\n",
        "transform = A.Compose([\n",
        "   # A.CLAHE(always_apply=True, p=1.0, clip_limit=(1, 4), tile_grid_size=(43, 34))\n",
        "   A.CLAHE(always_apply=True, p=1.0, clip_limit=(1, 2), tile_grid_size=(12, 6)),\n",
        "   A.HueSaturationValue(always_apply=True, p=1.0, hue_shift_limit=(0, 0), sat_shift_limit=(0, 14), val_shift_limit=(3, 0))\n",
        "])\n",
        "\n",
        "def loadAndCropCenterResizeCV2(img, newSize):\n",
        "    #img = cv.imread(imgPath)\n",
        "    width, height, ______ = img.shape\n",
        "    if width == height:\n",
        "        return cv.resize(img, newSize)\n",
        "    length = min(width, height)\n",
        "    left = (width - length) // 2\n",
        "    top = (height - length) // 2\n",
        "    right = (width + length) // 2\n",
        "    bottom = (height + length) // 2\n",
        "    return cv.resize(img[left:right, top:bottom, :], newSize)\n",
        "\n",
        "def clahe_resize(impath):\n",
        "  img = cv.imread(impath)\n",
        "\n",
        "  # Convert to RGB Color Space\n",
        "  image = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
        "\n",
        "  # Apply Albumentations Augmentation (CLAHE)\n",
        "  transformed = transform(image=image)\n",
        "  # Get result\n",
        "  transformed_image = transformed[\"image\"]\n",
        "  # Convert back to BGR colorspace\n",
        "  transformed_image_BGR = cv.cvtColor(transformed_image, cv.COLOR_BGR2RGBA)\n",
        "\n",
        "  #clahe = cv.createCLAHE(clipLimit=5.0, tileGridSize=(8,8))\n",
        "  #L, a, b = cv.split(cv.cvtColor(img, cv.COLOR_BGR2Lab))\n",
        "  #cl1 = clahe.apply(L)\n",
        "  #eq_image = cv.cvtColor(cv.merge([cl1, a, b]), cv.COLOR_Lab2BGR)\n",
        "\n",
        "  eq_image = loadAndCropCenterResizeCV2(transformed_image_BGR, (250, 250))\n",
        "\n",
        "\n",
        "  \n",
        "  cv.imwrite(impath,eq_image)\n",
        "\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnFnIa4OH_zT"
      },
      "source": [
        "# References: https://stackoverflow.com/questions/44650888/resize-an-image-without-distortion-opencv\n",
        "def resize_and_letter_box(image, rows, cols):\n",
        "    \"\"\"\n",
        "    Letter box (black bars) a color image (think pan & scan movie shown \n",
        "    on widescreen) if not same aspect ratio as specified rows and cols. \n",
        "    :param image: numpy.ndarray((image_rows, image_cols, channels), dtype=numpy.uint8)\n",
        "    :param rows: int rows of letter boxed image returned  \n",
        "    :param cols: int cols of letter boxed image returned\n",
        "    :return: numpy.ndarray((rows, cols, channels), dtype=numpy.uint8)\n",
        "    \"\"\"\n",
        "    image_rows, image_cols = image.shape[:2]\n",
        "    row_ratio = rows / float(image_rows)\n",
        "    col_ratio = cols / float(image_cols)\n",
        "    ratio = min(row_ratio, col_ratio)\n",
        "    image_resized = cv.resize(image, dsize=(0, 0), fx=ratio, fy=ratio)\n",
        "    letter_box = np.zeros((int(rows), int(cols), 3))\n",
        "    row_start = int((letter_box.shape[0] - image_resized.shape[0]) / 2)\n",
        "    col_start = int((letter_box.shape[1] - image_resized.shape[1]) / 2)\n",
        "    letter_box[row_start:row_start + image_resized.shape[0], col_start:col_start + image_resized.shape[1]] = image_resized\n",
        "    return letter_box\n",
        "\n",
        "# References https://note.nkmk.me/en/python-opencv-hconcat-vconcat-np-tile/\n",
        "def hconcat_resize_min(im_list, interpolation=cv.INTER_CUBIC):\n",
        "    h_min = min(im.shape[0] for im in im_list)\n",
        "    im_list_resize = [cv.resize(im, (int(im.shape[1] * h_min / im.shape[0]), h_min), interpolation=interpolation)\n",
        "                      for im in im_list]\n",
        "    return cv.hconcat(im_list_resize)\n",
        "\n",
        "\n",
        "def fuseImages(impath1, impath2, fusedPathName):\n",
        "  img1 = cv.imread(impath1)\n",
        "  img2 = cv.imread(impath2)\n",
        "\n",
        "\n",
        "  #fusion = \"SUM\"\n",
        "  if (fusionMethod == \"SUM\"):\n",
        "    img1Width = img1.shape[1]\n",
        "    img1Height = img1.shape[0]\n",
        "    print(\"Image1 width:\" + str(img1Width) + \" - Image1 height: \" + str(img1Height))\n",
        "\n",
        "    img2Width= img2.shape[1]\n",
        "    img2Height = img2.shape[0]\n",
        "    print(\"Image2 width:\" + str(img1Width) + \" - Image2 height: \" + str(img1Height))\n",
        "\n",
        "    if img1Width > img2Width:\n",
        "      img2 = resize_and_letter_box(img2, img1Height, img1Width)\n",
        "    else:\n",
        "      img1 =  resize_and_letter_box(img1, img2Height, img2Width)\n",
        "    \n",
        "\n",
        "    # img1 = img1.reshape(img2.shape)\n",
        "    fused = img1 + img2 #element wise sum\n",
        "\n",
        "  elif (fusionMethod == \"CONCAT\"):\n",
        "    fused = hconcat_resize_min([img1, img2])\n",
        "\n",
        "\n",
        "   \n",
        "\n",
        "  cv.imwrite(fusedPathName, fused)\n",
        "\n",
        "all_paths = []\n",
        "\n",
        "#images enhancing and resizing (takes a while ~19min)\n",
        "for imagePath in sorted(glob.glob(\"ODIR-5K/Training Images/*.jpg\")):\n",
        "  # Check if there is a left and right eye image  \n",
        "  imagePathSplit = imagePath.split(\"/\")\n",
        "  imageName = imagePathSplit[len(imagePathSplit) - 1]\n",
        "\n",
        "  imageNameSplit = imageName.split(\"_\")\n",
        "  imageIndex = imageNameSplit[0]\n",
        "  leftOrRight = imageNameSplit[1].split(\"-\")[0]\n",
        "  #print(\"Left or right: \" + leftOrRight)\n",
        "  if (leftOrRight == \"right\"):\n",
        "    # Since we're sorting all paths, left always occurs before right and we process both left/right images when we find the left eye\n",
        "    #print(\"Removing right: \" + imagePath)\n",
        "    os.remove(imagePath)\n",
        "    continue\n",
        "  \n",
        "  # Just incase, so we don't fuse more than once in the event this cell is ran multiple times\n",
        "  if (leftOrRight == \"fused\"):\n",
        "    continue\n",
        "\n",
        "  imagePairs = glob.glob(\"ODIR-5K/Training Images/\" + imageIndex + \"_*.jpg\")\n",
        "  #print(imagePairs)\n",
        "  if (len(imagePairs) != 2):\n",
        "    # Skip images that don't have a corresponding left and right eye image\n",
        "    os.remove(imagePath)\n",
        "    print(\"Removing cause there isint 2 images: \" + imagePath)\n",
        "    continue\n",
        "  \n",
        "  bothEyesDiseases = set()\n",
        "  for eyeImage in imagePairs:\n",
        "    # Get all the diseases of both eyes\n",
        "\n",
        "    # Get filename at end of path\n",
        "    eyeImagePathSplit = imagePath.split(\"/\")\n",
        "    eyeImageFilename = eyeImagePathSplit[len(eyeImagePathSplit) - 1]\n",
        "\n",
        "    # Remove file extension\n",
        "    base = eyeImageFilename.split(\".\")[0]\n",
        "\n",
        "    diseasesString = base.split(\"-\")[1]\n",
        "    diseases = diseasesString.split(\"&\")\n",
        "    for disease in diseases:\n",
        "      bothEyesDiseases.add(disease)\n",
        "\n",
        "  # Create the new filename\n",
        "  fusedFileName = imageIndex + \"_\" + \"fused\" + \"-\"\n",
        "  numDiseases = len(bothEyesDiseases)\n",
        "  count = 0\n",
        "  for disease in bothEyesDiseases:\n",
        "    fusedFileName += disease\n",
        "    count += 1\n",
        "    if count != numDiseases:\n",
        "      fusedFileName += \"&\"\n",
        "  \n",
        "  fusedFileName += \".jpg\"\n",
        "  #print(fusedFileName)\n",
        "  fusedFilePath = \"ODIR-5K/Training Images/\" + fusedFileName\n",
        "\n",
        "  # Now we can actually fuse the images together\n",
        "  if (fusionMethod != \"CONCAT\"):\n",
        "    fuseImages(imagePairs[0], imagePairs[1], fusedFilePath)\n",
        "    clahe_resize(fusedFilePath)\n",
        "  else:\n",
        "    # When concatenating, we apply enhancements and resize the images before concatenating them\n",
        "    clahe_resize(imagePairs[0])\n",
        "    clahe_resize(imagePairs[1])\n",
        "    fuseImages(imagePairs[0], imagePairs[1], fusedFilePath)\n",
        "\n",
        "  \n",
        "\n",
        "  all_paths.append(fusedFilePath)\n",
        "\n",
        "  # Delete the left eye image image\n",
        "  # TODO: Just make a new folder for fused images?..\n",
        "  os.remove(imagePath)\n",
        "\n",
        "\n",
        "\n",
        "# print(\"All paths: \" + str(all_paths))\n",
        "\n",
        "#images enhancing and resizing (takes a while ~19min)\n",
        "#all_paths = []\n",
        "#for element in sorted(glob.glob(\"ODIR-5K/Training Images/*.jpg\")):\n",
        "#  all_paths.append(element)\n",
        "#  clahe_resize(element)\n",
        "\n",
        "# Set a random seed so we always use the same validation set (which is randomly sampled from dataset)\n",
        "random.seed(7)\n",
        "\n",
        "#creating validation set\n",
        "# num_to_select = 1950\n",
        "num_to_select = int( 0.3 * len(all_paths))                         \n",
        "list_of_random_items = random.sample(sorted(all_paths), num_to_select)\n",
        "for element in list_of_random_items:\n",
        "  p = element.split(\"/\")\n",
        "  os.replace(element, \"ODIR-5K/Validation_Images/\"+p[-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FhykKECGeBvw"
      },
      "source": [
        "!rm -rf ODIR-5K/Testing\\ Images/\n",
        "!rm -rf ODIR-5K/data.xlsx\n",
        "!zip -r ODIR-5K_contrast.zip ODIR-5K/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxiG8gTkufNF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "058c8ca9-57ea-4668-cd90-2c8410f835e2"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/amd/')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /amd/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Koy6mYLujbg"
      },
      "source": [
        "!cp -r ODIR-5K_contrast.zip /amd/My\\ Drive/ML490"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8XGNtHWe3tF4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2375241e-9766-451f-db98-6d03d1c11c15"
      },
      "source": [
        "def show_class_distribution():\n",
        "  N = 0\n",
        "  D=0\n",
        "  G=0\n",
        "  C=0\n",
        "  A=0\n",
        "  H=0\n",
        "  M=0\n",
        "  O = 0\n",
        "  X = 0\n",
        "  for element in glob.glob(\"ODIR-5K/Training Images/*.jpg\"):\n",
        "    img_name = element.split(\"/\")[-1]\n",
        "    img_label = img_name.split(\"-\")\n",
        "    if img_label[-1] == \"N.jpg\":\n",
        "      N += 1\n",
        "    elif img_label[-1] == \"D.jpg\":\n",
        "      D +=1\n",
        "    elif img_label[-1] == \"G.jpg\":\n",
        "      G +=1\n",
        "    elif img_label[-1] == \"C.jpg\":\n",
        "      C +=1\n",
        "    elif img_label[-1] == \"A.jpg\":\n",
        "      A +=1\n",
        "    elif img_label[-1] == \"H.jpg\":\n",
        "      H +=1\n",
        "    elif img_label[-1] == \"M.jpg\":\n",
        "      M +=1\n",
        "    elif img_label[-1] == \"O.jpg\":\n",
        "      O +=1\n",
        "    elif \"&\" in img_label[-1]:\n",
        "      X +=1  \n",
        "  print(N, D, G, C, A, H, M, O, X)\n",
        "show_class_distribution()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "980 470 69 101 82 41 82 234 186\n"
          ]
        }
      ]
    }
  ]
}