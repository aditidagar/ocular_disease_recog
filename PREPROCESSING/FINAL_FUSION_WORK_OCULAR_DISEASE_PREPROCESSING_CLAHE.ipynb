{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FUSION WORK - OCULAR_DISEASE_PREPROCESSING_CLAHE.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aditidagar/ocular_disease_recog/blob/main/PREPROCESSING/FINAL_FUSION_WORK_OCULAR_DISEASE_PREPROCESSING_CLAHE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipUD93xtRH7E"
      },
      "source": [
        "First we download the dataset and organize it's directory structure to match the directory structure that the script expects. We have provided a kaggle.json key for convenience. NOTE: Often times, the first cell fails. It suffices to simply run it again for it to succeed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmUUgbNbAVjE"
      },
      "source": [
        "!echo '{\"username\":\"arturusmaximus\",\"key\":\"4f14194978499e9ae1ad6adb74b94add\"}' > /content/kaggle.json\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!kaggle datasets download -d andrewmvd/ocular-disease-recognition-odir5k\n",
        "!unzip ocular-disease-recognition-odir5k.zip\n",
        "!mv ODIR-5K ODIR-5K_old\n",
        "!mv ODIR-5K_old/ODIR-5K ODIR-5K\n",
        "!mkdir ODIR-5K/Validation_Images\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlA3W5pSRqTb"
      },
      "source": [
        "NOTE: This script is forked from Grezgor Meller's work: https://github.com/GrzegorzMeller/AlgorithmsForMassiveData/blob/master/Preprocessing/OCULAR_DISEASE_PREPROCESSING.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-mukUUUxAl7U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b364718-7500-4a15-9d22-9a4730b4e64e"
      },
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import os\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import IPython.display as display\n",
        "import numpy as np\n",
        "import glob\n",
        "import random\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "CLASS_NAMES = ['N', 'D', 'G', 'C', 'A', 'H', 'M', 'O']\n",
        "\n",
        "# Set a random seed so we always use the same validation set (which is randomly sampled from dataset)\n",
        "random.seed(7)\n",
        "\n",
        "training_images_file = 'ODIR-5K/Training Images'\n",
        "testing_images_file = 'ODIR-5K/Testing Images'\n",
        "labels_file = 'ODIR-5K/data.xlsx'\n",
        "\n",
        "\n",
        "# Classification of labels to diseases, as well as classification of unecessary images which should be deleted from the dataset\n",
        "diseases = {'abnormal pigment ': 'O', 'age-related macular degeneration': 'A', 'anterior segment image': 'DELETE', 'arteriosclerosis': 'O', 'asteroid hyalosis': 'O', 'atrophic change': 'O', 'atrophy': 'O', 'branch retinal artery occlusion': 'O', 'branch retinal vein occlusion': 'O', 'cataract': 'C', 'central retinal artery occlusion': 'O', 'central retinal vein occlusion': 'O', 'central serous chorioretinopathy': 'O', 'chorioretinal atrophy': 'O', 'chorioretinal atrophy with pigmentation proliferation': 'O', 'choroidal nevus': 'NaN', 'congenital choroidal coloboma': 'O', 'depigmentation of the retinal pigment epithelium': 'O', 'diabetic retinopathy': 'D', 'diffuse chorioretinal atrophy': 'O', 'diffuse retinal atrophy': 'O', 'drusen': 'O', 'dry age-related macular degeneration': 'A', 'epiretinal membrane': 'O', 'epiretinal membrane over the macula': 'O', 'fundus laser photocoagulation spots': 'O', 'glaucoma': 'G', 'glial remnants anterior to the optic disc': 'O', 'hypertensive retinopathy': 'H', 'hypertensive retinopathy,diabetic retinopathy': 'D', 'idiopathic choroidal neovascularization': 'O', 'image offset': 'DELETE', 'intraretinal hemorrhage': 'O', 'intraretinal microvascular abnormality': 'O', 'laser spot': 'O', 'lens dust': 'DELETE', 'low image quality': 'DELETE', 'low image quality,maculopathy': 'DELETE', 'macular coloboma': 'O', 'macular epiretinal membrane': 'O', 'macular hole': 'O', 'macular pigmentation disorder': 'NaN', 'maculopathy': 'O', 'mild nonproliferative retinopathy': 'D', 'moderate non proliferative retinopathy': 'D', 'morning glory syndrome': 'O', 'myelinated nerve fibers': 'O', 'myopia retinopathy': 'M', 'myopic maculopathy': 'M', 'myopic retinopathy': 'M', 'no fundus image': 'DELETE', 'normal fundus': 'N', 'old branch retinal vein occlusion': 'O', 'old central retinal vein occlusion': 'O', 'old chorioretinopathy': 'O', 'old choroiditis': 'O', 'optic disc edema': 'O', 'optic discitis': 'O', 'optic disk epiretinal membrane': 'O', 'optic disk photographically invisible': 'DELETE', 'optic nerve atrophy': 'O', 'oval yellow-white atrophy': 'O', 'pathological myopia': 'M', 'peripapillary atrophy': 'O', 'pigment epithelium proliferation': 'O', 'pigmentation disorder': 'O', 'post laser photocoagulation': 'O', 'post retinal laser surgery': 'O', 'proliferative diabetic retinopathy': 'D', 'punctate inner choroidopathy': 'O', 'refractive media opacity': 'O', 'retina fold': 'O', 'retinal artery macroaneurysm': 'O', 'retinal detachment': 'O', 'retinal pigment epithelial hypertrophy': 'O', 'retinal pigment epithelium atrophy': 'O', 'retinal pigmentation': 'O', 'retinal vascular sheathing': 'O', 'retinitis pigmentosa': 'O', 'retinochoroidal coloboma': 'O', 'rhegmatogenous retinal detachment': 'O', 'severe nonproliferative retinopathy': 'D', 'severe proliferative diabetic retinopathy': 'D', 'silicone oil eye': 'O', 'spotted membranous change': 'O', 'suspected abnormal color of  optic disc': 'O', 'suspected cataract': 'C', 'suspected diabetic retinopathy': 'D', 'suspected glaucoma': 'G', 'suspected macular epimacular membrane': 'O', 'suspected microvascular anomalies': 'O', 'suspected moderate non proliferative retinopathy': 'D', 'suspected retinal vascular sheathing': 'O', 'suspected retinitis pigmentosa': 'O', 'suspicious diabetic retinopathy': 'D', 'tessellated fundus': 'O', 'vascular loops': 'O', 'vessel tortuosity': 'O', 'vitreous degeneration': 'O', 'vitreous opacity': 'O', 'wedge white line change': 'O', 'wedge-shaped change': 'O', 'wet age-related macular degeneration': 'A', 'white vessel': 'O'}\n",
        "\n",
        "#load labels to pandas\n",
        "labels = pd.read_excel(labels_file, index_col=0) \n",
        "print(labels['Left-Diagnostic Keywords'][0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cataract\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "480GR6KOBj0C"
      },
      "source": [
        "Labeling Images by renaming them, removing low quality images "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KrYR14THAo4o"
      },
      "source": [
        "file_path = 'ODIR-5K/Training Images'\n",
        "all_paths = []\n",
        "for element in glob.glob(file_path+\"/*.jpg\"):\n",
        "  all_paths.append(element)\n",
        "paths = []\n",
        "\n",
        "\n",
        "#adding label information to image names\n",
        "for u_id in labels.index:\n",
        "  labelL = \"\"\n",
        "  labelR = \"\"\n",
        "  diagnosticL = labels['Left-Diagnostic Keywords'][u_id]\n",
        "  diagnosticR = labels['Right-Diagnostic Keywords'][u_id]\n",
        "  diagnosticL = diagnosticL.split(\"，\") \n",
        "  diagnosticR = diagnosticR.split(\"，\") \n",
        "\n",
        "  # For each eye, append all the diseases of the eye into a label that will be appended to the filename\n",
        "\n",
        "  for d in diagnosticL:\n",
        "    if d in diseases:\n",
        "        if labelL != \"\":\n",
        "          labelL+=\"&\"+diseases[d]\n",
        "        else:\n",
        "          labelL+=diseases[d]\n",
        "    else:\n",
        "        labelL+=\"DELETE\"\n",
        "  for d in diagnosticR:\n",
        "    if d in diseases:\n",
        "      if labelR != \"\":\n",
        "        labelR+=\"&\"+diseases[d]\n",
        "      else:\n",
        "        labelR+=diseases[d]\n",
        "    else:\n",
        "      labelR+=\"DELETE\"\n",
        "\n",
        "  if file_path+\"/\"+str(labels['Left-Fundus'][u_id]) in all_paths:\n",
        "    filename = str(labels['Left-Fundus'][u_id]).split(\".\")\n",
        "    os.rename(file_path+\"/\"+str(labels['Left-Fundus'][u_id]), file_path+\"/\"+filename[0]+\"-\"+labelL+\".jpg\")\n",
        "    paths.append(file_path+\"/\"+str(labels['Left-Fundus'][u_id])+\"/\"+labelL)\n",
        "\n",
        "  if file_path+\"/\"+str(labels['Right-Fundus'][u_id]) in all_paths:\n",
        "    filename = str(labels['Right-Fundus'][u_id]).split(\".\")\n",
        "    os.rename(file_path+\"/\"+str(labels['Right-Fundus'][u_id]), file_path+\"/\"+filename[0]+\"-\"+labelR+\".jpg\")\n",
        "    paths.append(file_path+\"/\"+str(labels['Right-Fundus'][u_id])+\"/\"+labelR)\n",
        "\n",
        "#deleting low quality & unecessary images    \n",
        "items_to_remove = []\n",
        "add_mix_info = []\n",
        "\n",
        "for element in glob.glob(\"ODIR-5K/Training Images/*.jpg\"):\n",
        "    img_name = element.split(\"/\")[-1]\n",
        "    img_label = img_name.split(\"-\")\n",
        "    if \"DELETE\" in img_label[-1]:\n",
        "      items_to_remove.append(element)\n",
        "    elif \"&\" in img_label[-1]:\n",
        "      add_mix_info.append(element)\n",
        "\n",
        "for e in items_to_remove:\n",
        "  os.remove(e)\n",
        "\n",
        "for e in add_mix_info:\n",
        "  pom = e.split(\".\")\n",
        "  os.rename(e, pom[0]+\"&X\"+\".jpg\")      "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEqFJtkJBaaC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZrNiunIST78"
      },
      "source": [
        "Install albumentations library for image enhancement"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3d019720",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3a26798-4791-463b-e771-fba5f90383c0"
      },
      "source": [
        "!pip install -q -U albumentations\n",
        "!echo \"$(pip freeze | grep albumentations) is successfully installed\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 102 kB 7.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 47.6 MB 68 kB/s \n",
            "\u001b[?25halbumentations==1.1.0 is successfully installed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocAsezPYScL1"
      },
      "source": [
        "# Only one of these lines should be uncommented to choose an image fusion method (or no fusion method using NONE)\n",
        "fusionMethod = \"NONE\"\n",
        "# fusionMethod = \"CONCAT\"\n",
        "# fusionMethod = \"SUM\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FFevHeGTEuml"
      },
      "source": [
        "Image Enhancement and Resizing.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6BLEIpj-Etpj"
      },
      "source": [
        "import cv2 as cv\n",
        "import albumentations as A\n",
        "\n",
        "# Albumentations CLAHE and HSV parameters.\n",
        "transform = A.Compose([\n",
        "   A.CLAHE(always_apply=True, p=1.0, clip_limit=(1, 2), tile_grid_size=(12, 6)),\n",
        "   A.HueSaturationValue(always_apply=True, p=1.0, hue_shift_limit=(0, 0), sat_shift_limit=(0, 14), val_shift_limit=(3, 0))\n",
        "])\n",
        "\n",
        "def loadAndCropCenterResizeCV2(img, newSize):\n",
        "    width, height, ______ = img.shape\n",
        "    if width == height:\n",
        "        return cv.resize(img, newSize)\n",
        "    length = min(width, height)\n",
        "    left = (width - length) // 2\n",
        "    top = (height - length) // 2\n",
        "    right = (width + length) // 2\n",
        "    bottom = (height + length) // 2\n",
        "    return cv.resize(img[left:right, top:bottom, :], newSize)\n",
        "\n",
        "def clahe_resize(impath):\n",
        "  img = cv.imread(impath)\n",
        "\n",
        "  # Convert to RGB color space, which Albumentations uses (OpenCV uses BGR colorspace)\n",
        "  image = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
        "\n",
        "  # Apply Albumentations Augmentation (CLAHE and HSV)\n",
        "  transformed = transform(image=image)\n",
        "  # Get result\n",
        "  transformed_image = transformed[\"image\"]\n",
        "  # Convert back to BGR colorspace\n",
        "  transformed_image_BGR = cv.cvtColor(transformed_image, cv.COLOR_BGR2RGBA)\n",
        "\n",
        "  eq_image = loadAndCropCenterResizeCV2(transformed_image_BGR, (250, 250))\n",
        "  \n",
        "  cv.imwrite(impath,eq_image)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJFm6KJ5WPHC"
      },
      "source": [
        "Image fusion and creation of validation set through random selection/sampling of the training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnFnIa4OH_zT"
      },
      "source": [
        "# References: https://stackoverflow.com/questions/44650888/resize-an-image-without-distortion-opencv\n",
        "# This function is used when performing an element-wise sum of two eye images.\n",
        "# It is used to ensure both eye images are of the same size, and adds black space (letter boxing) around the image if necessary\n",
        "def resize_and_letter_box(image, rows, cols):\n",
        "    \"\"\"\n",
        "    Letter box (black bars) a color image (think pan & scan movie shown \n",
        "    on widescreen) if not same aspect ratio as specified rows and cols. \n",
        "    :param image: numpy.ndarray((image_rows, image_cols, channels), dtype=numpy.uint8)\n",
        "    :param rows: int rows of letter boxed image returned  \n",
        "    :param cols: int cols of letter boxed image returned\n",
        "    :return: numpy.ndarray((rows, cols, channels), dtype=numpy.uint8)\n",
        "    \"\"\"\n",
        "    image_rows, image_cols = image.shape[:2]\n",
        "    row_ratio = rows / float(image_rows)\n",
        "    col_ratio = cols / float(image_cols)\n",
        "    ratio = min(row_ratio, col_ratio)\n",
        "    image_resized = cv.resize(image, dsize=(0, 0), fx=ratio, fy=ratio)\n",
        "    letter_box = np.zeros((int(rows), int(cols), 3))\n",
        "    row_start = int((letter_box.shape[0] - image_resized.shape[0]) / 2)\n",
        "    col_start = int((letter_box.shape[1] - image_resized.shape[1]) / 2)\n",
        "    letter_box[row_start:row_start + image_resized.shape[0], col_start:col_start + image_resized.shape[1]] = image_resized\n",
        "    return letter_box\n",
        "\n",
        "# References https://note.nkmk.me/en/python-opencv-hconcat-vconcat-np-tile/\n",
        "# This function is used to horizontally concatenate both eye images when the concatenation image fusion method is used.\n",
        "# The larger image is resized to the smaller image size before concatenating them together.\n",
        "def hconcat_resize_min(im_list, interpolation=cv.INTER_CUBIC):\n",
        "    h_min = min(im.shape[0] for im in im_list)\n",
        "    im_list_resize = [cv.resize(im, (int(im.shape[1] * h_min / im.shape[0]), h_min), interpolation=interpolation)\n",
        "                      for im in im_list]\n",
        "    return cv.hconcat(im_list_resize)\n",
        "\n",
        "\n",
        "def fuseImages(impath1, impath2, fusedPathName):\n",
        "  img1 = cv.imread(impath1)\n",
        "  img2 = cv.imread(impath2)\n",
        "\n",
        "  if (fusionMethod == \"SUM\"):\n",
        "    img1Width = img1.shape[1]\n",
        "    img1Height = img1.shape[0]\n",
        "    # print(\"Image1 width:\" + str(img1Width) + \" - Image1 height: \" + str(img1Height))\n",
        "\n",
        "    img2Width= img2.shape[1]\n",
        "    img2Height = img2.shape[0]\n",
        "    # print(\"Image2 width:\" + str(img1Width) + \" - Image2 height: \" + str(img1Height))\n",
        "\n",
        "    if img1Width > img2Width:\n",
        "      img2 = resize_and_letter_box(img2, img1Height, img1Width)\n",
        "    else:\n",
        "      img1 =  resize_and_letter_box(img1, img2Height, img2Width)\n",
        "\n",
        "    fused = img1 + img2 #element wise sum since we have two Numpy arrays\n",
        "\n",
        "  elif (fusionMethod == \"CONCAT\"):\n",
        "    fused = hconcat_resize_min([img1, img2])\n",
        "\n",
        "  cv.imwrite(fusedPathName, fused)\n",
        "\n",
        "all_paths = []\n",
        "\n",
        "def fuseAndEnhance():\n",
        "  for imagePath in sorted(glob.glob(\"ODIR-5K/Training Images/*.jpg\")):\n",
        "    # Check if there is a left and right eye image  \n",
        "    imagePathSplit = imagePath.split(\"/\")\n",
        "    imageName = imagePathSplit[len(imagePathSplit) - 1]\n",
        "\n",
        "    imageNameSplit = imageName.split(\"_\")\n",
        "    imageIndex = imageNameSplit[0]\n",
        "    leftOrRight = imageNameSplit[1].split(\"-\")[0]\n",
        "\n",
        "    if (leftOrRight == \"right\"):\n",
        "      # Since we're sorting all paths, left always occurs before right and we process both left/right images when we find the left eye\n",
        "      #print(\"Removing right: \" + imagePath)\n",
        "      os.remove(imagePath)\n",
        "      continue\n",
        "    \n",
        "    # Just incase, so we don't fuse more than once in the event this cell is ran multiple times, though it should never be ran multiple times..\n",
        "    if (leftOrRight == \"fused\"):\n",
        "      continue\n",
        "\n",
        "    # Find both the left and right eye images that have the same image index (image number)\n",
        "    imagePairs = glob.glob(\"ODIR-5K/Training Images/\" + imageIndex + \"_*.jpg\")\n",
        "    #print(imagePairs)\n",
        "    if (len(imagePairs) != 2):\n",
        "      # Skip images that don't have a corresponding left and right eye image\n",
        "      os.remove(imagePath)\n",
        "      print(\"Removing because there is not 2 images: \" + imagePath)\n",
        "      continue\n",
        "    \n",
        "    # Get all the diseases of both eyes\n",
        "    bothEyesDiseases = set()\n",
        "    for eyeImage in imagePairs:\n",
        " \n",
        "      # Get filename at end of path\n",
        "      eyeImagePathSplit = imagePath.split(\"/\")\n",
        "      eyeImageFilename = eyeImagePathSplit[len(eyeImagePathSplit) - 1]\n",
        "\n",
        "      # Remove file extension\n",
        "      base = eyeImageFilename.split(\".\")[0]\n",
        "\n",
        "      diseasesString = base.split(\"-\")[1]\n",
        "      diseases = diseasesString.split(\"&\")\n",
        "      for disease in diseases:\n",
        "        bothEyesDiseases.add(disease)\n",
        "\n",
        "    # Create the new filename\n",
        "    fusedFileName = imageIndex + \"_\" + \"fused\" + \"-\"\n",
        "    numDiseases = len(bothEyesDiseases)\n",
        "    count = 0\n",
        "    for disease in bothEyesDiseases:\n",
        "      fusedFileName += disease\n",
        "      count += 1\n",
        "      if count != numDiseases:\n",
        "        fusedFileName += \"&\"\n",
        "    \n",
        "    fusedFileName += \".jpg\"\n",
        "    #print(fusedFileName)\n",
        "    fusedFilePath = \"ODIR-5K/Training Images/\" + fusedFileName\n",
        "\n",
        "    # Now we can actually fuse the images together\n",
        "    if (fusionMethod != \"CONCAT\"):\n",
        "      fuseImages(imagePairs[0], imagePairs[1], fusedFilePath)\n",
        "      clahe_resize(fusedFilePath)\n",
        "    else:\n",
        "      # When concatenating, we apply enhancements and resize the images before concatenating them\n",
        "      clahe_resize(imagePairs[0])\n",
        "      clahe_resize(imagePairs[1])\n",
        "      fuseImages(imagePairs[0], imagePairs[1], fusedFilePath)\n",
        "\n",
        "    \n",
        "\n",
        "    all_paths.append(fusedFilePath)\n",
        "\n",
        "    # Delete the left eye image image\n",
        "    # We could have just made another folder for fused images, but this is simpler so that we don't have to modify the models further\n",
        "    os.remove(imagePath)\n",
        "\n",
        "if fusionMethod == \"NONE\":\n",
        "  for element in sorted(glob.glob(\"ODIR-5K/Training Images/*.jpg\")):\n",
        "   all_paths.append(element)\n",
        "   clahe_resize(element)\n",
        "else:\n",
        "  fuseAndEnhance()\n",
        "\n",
        "# Set a random seed so we always use the same validation set (which is randomly sampled from dataset)\n",
        "random.seed(7)\n",
        "\n",
        "# Creation of the validation set using 30% of the images from the training set\n",
        "num_to_select = int( 0.3 * len(all_paths))                         \n",
        "list_of_random_items = random.sample(sorted(all_paths), num_to_select)\n",
        "for element in list_of_random_items:\n",
        "  p = element.split(\"/\")\n",
        "  os.replace(element, \"ODIR-5K/Validation_Images/\"+p[-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FhykKECGeBvw"
      },
      "source": [
        "!rm -rf ODIR-5K/Testing\\ Images/\n",
        "!rm -rf ODIR-5K/data.xlsx\n",
        "!zip -r ODIR-5K_contrast.zip ODIR-5K/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxiG8gTkufNF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c7501de-5c82-45b2-b881-d2fce183a325"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/amd/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /amd/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFkjLPxYVdA6"
      },
      "source": [
        "NOTE: Our code assumes you have a directory in your Google Drive called \"ML490\". Either create a ML490 folder or change the path below, though make sure you also adjust the path in the augmentation script as well as the model scripts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Koy6mYLujbg"
      },
      "source": [
        "!cp -r ODIR-5K_contrast.zip /amd/My\\ Drive/ML490"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8XGNtHWe3tF4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c69223c4-c10d-4ea3-f758-9a7009e7fdd7"
      },
      "source": [
        "def show_class_distribution():\n",
        "  N = 0\n",
        "  D=0\n",
        "  G=0\n",
        "  C=0\n",
        "  A=0\n",
        "  H=0\n",
        "  M=0\n",
        "  O = 0\n",
        "  X = 0\n",
        "  for element in glob.glob(\"ODIR-5K/Training Images/*.jpg\"):\n",
        "    img_name = element.split(\"/\")[-1]\n",
        "    img_label = img_name.split(\"-\")\n",
        "    if img_label[-1] == \"N.jpg\":\n",
        "      N += 1\n",
        "    elif img_label[-1] == \"D.jpg\":\n",
        "      D +=1\n",
        "    elif img_label[-1] == \"G.jpg\":\n",
        "      G +=1\n",
        "    elif img_label[-1] == \"C.jpg\":\n",
        "      C +=1\n",
        "    elif img_label[-1] == \"A.jpg\":\n",
        "      A +=1\n",
        "    elif img_label[-1] == \"H.jpg\":\n",
        "      H +=1\n",
        "    elif img_label[-1] == \"M.jpg\":\n",
        "      M +=1\n",
        "    elif img_label[-1] == \"O.jpg\":\n",
        "      O +=1\n",
        "    elif \"&\" in img_label[-1]:\n",
        "      X +=1  \n",
        "  print(N, D, G, C, A, H, M, O, X)\n",
        "show_class_distribution()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1974 978 139 178 167 77 170 520 392\n"
          ]
        }
      ]
    }
  ]
}